{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gunsin00/Autonomous-Robot/blob/main/Copy_of_One_hidden_layer_perceptron_to_recognize_MNIST_(200_train_200_test)_SWChoi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "G5kF3hLxe7bo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot\n",
        "\n",
        "class Perceptron: # Perceptron이라는 class 정의\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, activation, lr=0.01): #self라는 함수에, input_dim과 Hidden_dim, Output_dim을 입력하고 lr = 0.01)\n",
        "        self.w1 =  np.random.normal(0.0, pow(hidden_dim, -0.5), (input_dim, hidden_dim)) #self라는 함수의 w1이라는 속성을 설정, 해당 속성은 정규분표 중 평균 0, 표준편차 pow(hidden_dim, -0.5), \n",
        "        self.w2 =  np.random.normal(0.0, pow(hidden_dim, -0.5), (hidden_dim, output_dim))\n",
        "        self.h = np.zeros((1,hidden_dim))\n",
        "        self.lr = lr\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.activation = activation\n",
        "        self.theta = 0\n",
        "\n",
        "    def softmax(self, x):\n",
        "        e_x = np.exp(x - np.max(x))\n",
        "        return e_x / e_x.sum(axis=0) # only difference\n",
        "        \n",
        "    def sigmoid(self, x):\n",
        "        a= 1/(1+np.exp(-x))\n",
        "        return 1/(1+np.exp(-x))\n",
        "\n",
        "    def relu(self, x):\n",
        "        ax = tuple[x.numpy.ndarray, x.numpy.ndarray]\n",
        "        print(ax)\n",
        "        return ax\n",
        "\n",
        "    def tanh(self, x):\n",
        "        return (2/(1+np.exp(-x))) - 1\n",
        "\n",
        "    def feedforward(self, x, activation):\n",
        "        a = x.astype(float)\n",
        "        b = self.w1.astype(float)\n",
        "\n",
        "        if activation == \"sigmoid\" :\n",
        "            self.h = self.sigmoid(np.dot(a, b)- self.theta)\n",
        "            self.h1 = self.sigmoid(np.dot(self.h, self.w2)- self.theta)\n",
        "\n",
        "        elif activation == \"relu\" :\n",
        "            self.h = self.relu(np.dot(a, b) - self.theta)\n",
        "            self.h1 = self.relu(np.dot(self.h, self.w2)- self.theta)\n",
        "\n",
        "        elif activation == \"tanh\" :\n",
        "            self.h = self.tanh(np.dot(a, b) - self.theta)\n",
        "            self.h1 = self.tanh(np.dot(self.h, self.w2)- self.theta)\n",
        "\n",
        "        return self.h1\n",
        "\n",
        "    def feedforward_upto_hidden(self, x, activation):\n",
        "\n",
        "        if activation == \"sigmoid\" :\n",
        "            self.h2 = self.sigmoid(np.dot(x, self.w1)- self.theta)\n",
        "\n",
        "        elif activation == \"relu\" :\n",
        "            self.h2 = self.relu(np.dot(x, self.w1)- self.theta)\n",
        "\n",
        "        elif activation == \"tanh\" :\n",
        "            self.h2 = self.tanh(np.dot(x, self.w1)- self.theta)\n",
        "\n",
        "        return self.h2\n",
        "\n",
        "\n",
        "    def sigmoid_backward(self, y):\n",
        "        dy = y*(1-y)\n",
        "        return dy\n",
        "\n",
        "    def relu_backward(self, y): \n",
        "        dy = y\n",
        "        dy[y <= 0] = 0\n",
        "        dy[y > 0] = 1\n",
        "        return dy\n",
        "        \n",
        "    def tanh_backward(self, y):\n",
        "        dy = 1 - (np.tanh(-y)**2)\n",
        "        return dy\n",
        "        \n",
        "    def bprop_w2(self, g, y, activation): # target, output\n",
        "\n",
        "        if activation == \"sigmoid\" :\n",
        "          q = (-2)*(g-y)*self.sigmoid_backward(y)\n",
        "          bq_w2 = np.dot(self.h.reshape(self.hidden_dim,1), q.reshape(1,self.output_dim))\n",
        "\n",
        "        elif activation == \"relu\" :\n",
        "          q = (-2)*(g-y)*self.relu_backward(y)\n",
        "          bq_w2 = np.dot(self.h.reshape(self.hidden_dim,1), q.reshape(1,self.output_dim))\n",
        "\n",
        "        elif activation == \"tanh\" :\n",
        "          q = (-2)*(g-y)*self.tanh_backward(y)\n",
        "          bq_w2 = np.dot(self.h.reshape(self.hidden_dim,1), q.reshape(1,self.output_dim))\n",
        "\n",
        "        return bq_w2\n",
        "\n",
        "    def bprop_w1(self, g, y, x, activation): # target, output, input\n",
        "\n",
        "        if activation == \"sigmoid\" :\n",
        "          q1 = (-2)*(g-y)*self.sigmoid_backward(y)\n",
        "          q2 = np.dot(self.w2, q1)\n",
        "          bq_w1 = np.dot(x.reshape(self.input_dim, 1), q2*self.h*(1-self.h).reshape(1,self.hidden_dim))\n",
        "\n",
        "        elif activation == \"relu\" :\n",
        "          q1 = (-2)*(g-y)*self.relu_backward(y)\n",
        "          q2 = np.dot(self.w2, q1)\n",
        "          #print(q2)\n",
        "          bq_w1 = np.dot(x.reshape(self.input_dim, 1), q2*self.h*(1-self.h).reshape(1,self.hidden_dim))\n",
        "\n",
        "        elif activation == \"tanh\" :\n",
        "          q1 = (-2)*(g-y)*self.tanh_backward(y)\n",
        "          q2 = np.dot(self.w2, q1)\n",
        "          bq_w1 = np.dot(x.reshape(self.input_dim, 1), q2*self.h*(1-self.h).reshape(1,self.hidden_dim))\n",
        "\n",
        "        return bq_w1\n",
        "\n",
        "    def training(self, input, target, activation):\n",
        "        x = np.array(input).T\n",
        "        y = self.feedforward(x, activation)\n",
        "        g = np.array(target).T\n",
        "            \n",
        "        self.w1 = self.w1 - self.lr*self.bprop_w1(g, y, x, activation)\n",
        "        self.w2 = self.w2 - self.lr*self.bprop_w2(g, y, activation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "mzSYwwgme7bp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad4899da-f70b-449d-8390-60c3759dd547"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: RuntimeWarning: overflow encountered in exp\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "input_dim = 784\n",
        "hidden_dim = 100\n",
        "output_dim = 10\n",
        "activation = \"tanh\"\n",
        "epoch = 100\n",
        "\n",
        "pct = Perceptron(784,100,10,\"tanh\", lr=0.1)\n",
        "\n",
        "training_dataset_file = open(\"mnist_train_200.csv\", 'r')\n",
        "#training_dataset_file = open(\"mnist_train.csv\", 'r')\n",
        "\n",
        "training_dataset_list = training_dataset_file.readlines()\n",
        "training_dataset_file.close()\n",
        "input_list = list()\n",
        "\n",
        "for k in range(epoch):\n",
        "    pct.lr = pct.lr * 0.8  # learning lrate decay\n",
        "    for i in training_dataset_list:\n",
        "        all_values = i.split(',')\n",
        "        inputs = (np.asfarray(all_values[1:])/255.0*0.99)+0.01\n",
        "        input_list.append(inputs)\n",
        "        \n",
        "        targets = np.zeros(output_dim) + 0.01\n",
        "        targets[int(all_values[0])] = 0.99\n",
        "        \n",
        "        pct.training(inputs, targets, activation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "eEV76Yz9e7bq"
      },
      "outputs": [],
      "source": [
        "# Test\n",
        "test_dataset_file = open(\"mnist_test_200.csv\", 'r')\n",
        "#test_dataset_file = open(\"mnist_test.csv\", 'r')\n",
        "\n",
        "test_dataset_list = test_dataset_file.readlines()\n",
        "test_dataset_file.close()\n",
        "output_list = list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjXZYuZCe7bq",
        "outputId": "dd0a855b-1d27-4acc-f1ef-a4a7901d58df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: RuntimeWarning: overflow encountered in exp\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.00227166, -0.14932788,  0.81328911,  0.58962809,  0.17855226,\n",
              "        0.03377914,  0.03490213, -0.18540014,  0.14448099, -0.10198848])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "all_values = test_dataset_list[0].split(',')\n",
        "print(all_values[0])\n",
        "pct.feedforward(np.asfarray(all_values[1:]),activation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwv9Rn6Ae7bq",
        "outputId": "0c0faa07-2e8d-4a02-b6b9-908d49011be9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconition errio rate =  0.905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: RuntimeWarning: overflow encountered in exp\n"
          ]
        }
      ],
      "source": [
        "# Test error rate\n",
        "success = 0\n",
        "failure = 0\n",
        "\n",
        "for i in test_dataset_list:\n",
        "    all_values = i.split(',')\n",
        "    target = int(all_values[0])\n",
        "    \n",
        "    #inputs = (np.asfarray(all_values[1:])/255.0*0.99)+0.01\n",
        "    prediction_list = pct.feedforward(np.asfarray(all_values[1:]), activation)\n",
        "    prediction = np.argmax(prediction_list)\n",
        "    \n",
        "    if target == prediction:\n",
        "        success = success + 1\n",
        "        #print(\"Prediction is successful. (target, predcition) = \", target, prediction )\n",
        "    else:\n",
        "        failure = failure + 1\n",
        "        #print(\"Prediction fails. (target, predcition) = \", target, prediction )\n",
        "        \n",
        "print(\"Reconition errio rate = \", (failure/(success+failure)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MbbgUiae7br"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}